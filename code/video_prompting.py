import os
import json
import torch
from tqdm import tqdm  # è¿›åº¦æ¡åº“
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
from qwen_vl_utils import process_vision_info

# è®¾ç½®ç›®å½•è·¯å¾„
video_dir = r"/root/autodl-tmp/è§†é¢‘/å†’çŠ¯"  # ç›´æ¥å¤„ç†è§†é¢‘æ–‡ä»¶
output_json_path = "/root/autodl-tmp/test.json"  # ç»“æœä¿å­˜è·¯å¾„
failed_json_path = "/root/autodl-tmp/offensive_fail_all.json"  # å¤±è´¥è§†é¢‘è®°å½•è·¯å¾„

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
model_path = "/root/autodl-tmp/Qwen2.5-VL-7B-Instruct"
model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    model_path, torch_dtype="auto", device_map="auto"
)
processor = AutoProcessor.from_pretrained(model_path)

# æç¤ºè¯
PROMPTS = {
    "1": "è§†é¢‘ä¸»ä½“æŒ‡çš„æ˜¯è§†é¢‘ä¸­æœ€ä¸»è¦çš„è§’è‰²ã€å¯¹è±¡æˆ–å…ƒç´ ã€‚å‡å¦‚ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘åˆ†æå‘˜ã€‚åŸºäºç»™å®šçš„çŸ­è§†é¢‘ï¼Œè¯·å®šä½è¯¥è§†é¢‘çš„ä¸»ä½“ï¼Œå¹¶ä»¥ä»¥ä¸‹çš„æ ¼å¼è¾“å‡ºè¯¥çŸ­è§†é¢‘çš„ä¸»ä½“ç±»å‹ï¼š{äººç±»ä¸»ä½“/å…¶ä»–ä¸»ä½“}",
    "1-1": "è¯¥çŸ­è§†é¢‘ä»¥äººç±»ä¸ºä¸»ä½“ï¼Œè¯·ä»äººç±»ä¸»ä½“çš„å¤–è§‚ã€è¡Œä¸ºã€æƒ…ç»ªã€è¯­è¨€å››ä¸ªè§’åº¦å¯¹å…¶è¿›è¡Œè¯¦ç»†æè¿°ä¸ç»¼åˆåˆ†æã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š{ä¸»ä½“æè¿°ï¼šâ€œå¤–è§‚ï¼š ï¼›è¡Œä¸ºï¼š ï¼›æƒ…ç»ªï¼š ï¼›è¯­è¨€ï¼šâ€ä¸»ä½“ç»¼åˆåˆ†æï¼š}",
    "1-2": "è¯¥çŸ­è§†é¢‘ä¸»ä½“å¹¶éæ˜¯äººç±»ï¼Œè¯·ç»™å‡ºè¯¥çŸ­è§†é¢‘ä¸»ä½“çš„è¯¦ç»†æè¿°ä¸ç»¼åˆåˆ†æã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š{ä¸»ä½“æè¿°ï¼šâ€œ â€ä¸»ä½“ç»¼åˆåˆ†æï¼šâ€œ â€}",
    "2": "åŸºäºç»™å®šçš„çŸ­è§†é¢‘ï¼Œåˆ¤æ–­è¯¥è§†é¢‘æ˜¯å¦å­˜åœ¨ä¸€ä¸ªå¯ä»¥ä½œä¸ºä¸»çº¿çš„äº‹ä»¶ã€‚è‹¥å­˜åœ¨æ˜ç¡®çš„ä¸»çº¿äº‹ä»¶ï¼Œè¯·å°†å…¶åˆ†ç±»ä¸ºâ€˜äº‹ä»¶å‹â€™ï¼›è‹¥æ²¡æœ‰æ˜ç¡®çš„ä¸»çº¿äº‹ä»¶ï¼Œä¸”å†…å®¹è¾ƒä¸ºé›¶æ•£æˆ–ä¸å…·å¤‡ä¸»çº¿æƒ…èŠ‚ï¼Œè¯·å°†å…¶åˆ†ç±»ä¸ºâ€˜éäº‹ä»¶å‹â€™ã€‚è¾“å‡ºæ ¼å¼{äº‹ä»¶å‹/éäº‹ä»¶å‹}",
    "2-1": "è¯¥çŸ­è§†é¢‘æ˜¯äº‹ä»¶å‹ï¼Œè¯·ä»äº‹ä»¶çš„æ—¶é—´ã€åœ°ç‚¹ã€äººç‰©ã€èµ·å› ã€ç»è¿‡ã€ç»“æœè¿™å…­ä¸ªè§’åº¦è¿›è¡Œæ€è€ƒï¼Œç»™å‡ºå¯¹è¯¥äº‹ä»¶çš„è¯¦ç»†æè¿°å’Œç»¼åˆåˆ†æã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š{å†…å®¹æè¿°ï¼šâ€œæ—¶é—´ï¼šï¼›åœ°ç‚¹ï¼šï¼›äººç‰©ï¼šï¼›äº‹ä»¶èµ·å› ï¼šï¼›äº‹ä»¶ç»è¿‡ï¼šï¼›äº‹ä»¶ç»“æœï¼šï¼›â€å†…å®¹ç»¼åˆåˆ†æï¼š}",
    "2-2": "è¯¥çŸ­è§†é¢‘æ˜¯éäº‹ä»¶å‹ï¼Œè¯·ç»™å‡ºè§†é¢‘å†…å®¹çš„è¯¦ç»†æè¿°å’Œç»¼åˆåˆ†æã€‚è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š{å†…å®¹æè¿°ï¼šå†…å®¹ç»¼åˆåˆ†æï¼š}",
}

# è¯»å–å·²å¤„ç†å’Œå¤±è´¥çš„è§†é¢‘åˆ—è¡¨
def load_processed_videos():
    """åŠ è½½å·²å¤„ç†å’Œå¤±è´¥çš„è§†é¢‘ IDï¼Œé¿å…é‡å¤å¤„ç†"""
    processed = set()
    failed = set()

    # è¯»å–å·²å¤„ç†è§†é¢‘
    if os.path.exists(output_json_path):
        with open(output_json_path, "r", encoding="utf-8") as f:
            try:
                data = json.load(f)
                processed = {entry["video_id"] for entry in data}
            except json.JSONDecodeError:
                pass

    # è¯»å–å¤±è´¥è§†é¢‘
    if os.path.exists(failed_json_path):
        with open(failed_json_path, "r", encoding="utf-8") as f:
            try:
                failed = set(json.load(f))
            except json.JSONDecodeError:
                pass

    return processed, failed

# è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶
def get_video_files(directory):
    """è·å–æ‰€æœ‰ MP4 æ ¼å¼çš„è§†é¢‘æ–‡ä»¶"""
    video_files = {}
    for filename in sorted(os.listdir(directory)):  # ç¡®ä¿é¡ºåº
        if filename.endswith(".mp4"):  # åªå¤„ç† MP4 è§†é¢‘
            video_id = os.path.splitext(filename)[0]  # å»æ‰åç¼€
            video_files[video_id] = os.path.join(directory, filename)
    return video_files

# å‘ Qwen æäº¤è¯·æ±‚
def query_qwen(video_path, prompt):
    """å‘ Qwen æäº¤è¯·æ±‚ï¼Œè·å–ç”Ÿæˆçš„æ–‡æœ¬"""
    messages = [
        {
            "role": "user",
            "content": [
                {
                    "type": "video",
                    "video": f"file://{video_path}",
                    "max_pixels": 180 * 210,
                    "fps": 1.0,
                },
                {"type": "text", "text": prompt},
            ],
        }
    ]

    # é¢„å¤„ç†è¾“å…¥
    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    image_inputs, video_inputs, video_kwargs = process_vision_info(messages, return_video_kwargs=True)
    
    inputs = processor(
        text=[text],
        images=image_inputs,
        videos=video_inputs,
        padding=True,
        return_tensors="pt",
        **video_kwargs,
    ).to("cuda")

    # ç”Ÿæˆç»“æœ
    generated_ids = model.generate(**inputs, max_new_tokens=256)
    generated_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
    ]
    output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True)[0]
    
    return output_text

# å¤„ç†è§†é¢‘
def process_videos(video_files):
    """å¯¹æ¯ä¸ªè§†é¢‘è¿›è¡Œå®Œæ•´çš„åˆ†æ"""
    results = []
    processed_videos, failed_videos = load_processed_videos()
    failed_videos = set(failed_videos)  # ç¡®ä¿å®ƒæ˜¯å¯å˜çš„é›†åˆ
    total_videos = len(video_files)

    with tqdm(total=total_videos, desc="ğŸ“Š è§†é¢‘åˆ†æè¿›åº¦", unit="video") as pbar:
        for video_id, video_path in video_files.items():
            if video_id in processed_videos:
                print(f"â­ï¸ è·³è¿‡ {video_id} (å·²å®Œæˆ)")
                pbar.update(1)
                continue  # è·³è¿‡å·²å®Œæˆçš„è§†é¢‘
            
            if video_id in failed_videos:
                print(f"âš ï¸ è·³è¿‡ {video_id} (ä¹‹å‰å¤±è´¥)")
                pbar.update(1)
                continue  # è·³è¿‡å¤±è´¥çš„è§†é¢‘

            print(f"\nğŸš€ Processing video: {video_id}")
            
            try:
                subject_type = query_qwen(video_path, PROMPTS["1"]).strip()
                if "äººç±»ä¸»ä½“" in subject_type:
                    subject_analysis = query_qwen(video_path, PROMPTS["1-1"])
                else:
                    subject_analysis = query_qwen(video_path, PROMPTS["1-2"])

                event_type = query_qwen(video_path, PROMPTS["2"]).strip()
                if "äº‹ä»¶å‹" in event_type:
                    content_analysis = query_qwen(video_path, PROMPTS["2-1"])
                else:
                    content_analysis = query_qwen(video_path, PROMPTS["2-2"])

                video_result = {
                    "video_id": video_id,
                    "ä¸»ä½“åˆ†æ": subject_analysis,
                    "å†…å®¹åˆ†æ": content_analysis
                }
                results.append(video_result)

                # è¿½åŠ æ–°ç»“æœï¼Œè€Œä¸æ˜¯è¦†ç›–å·²æœ‰çš„
                with open(output_json_path, "w", encoding="utf-8") as f:
                    json.dump(results, f, ensure_ascii=False, indent=4)

            except Exception as e:
                print(f"âŒ å¤„ç† {video_id} å¤±è´¥: {e}")
                failed_videos.add(video_id)  # æ›´æ–°å¤±è´¥çš„è§†é¢‘é›†åˆ
                
                # è®°å½•æ‰€æœ‰å¤±è´¥çš„è§†é¢‘
                with open(failed_json_path, "w", encoding="utf-8") as f:
                    json.dump(list(failed_videos), f, ensure_ascii=False, indent=4)

            pbar.update(1)

if __name__ == "__main__":
    video_files = get_video_files(video_dir)
    process_videos(video_files)
    print(f"\nâœ… Analysis complete. Results saved to {output_json_path}")
